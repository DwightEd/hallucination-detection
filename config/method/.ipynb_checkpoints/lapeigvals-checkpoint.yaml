# =============================================================================
# LapEigvals - Laplacian Eigenvalue-based Hallucination Detection
# =============================================================================
# 论文: Hallucination Detection in LLMs Using Spectral Features of Attention Maps
# 链接: https://github.com/graphml-lab-pwr/lapeigvals (EMNLP 2025)
# =============================================================================

name: lapeigvals
cls_path: src.methods.lapeigvals.LapEigvalsMethod

# ============ 基础信息 ============
level: sample
classifier: logistic
random_seed: ${seed}

# =============================================================================
# 特征配置 - 关键: 需要完整注意力或预计算的laplacian_diags
# =============================================================================
features:
  # 需要完整注意力矩阵来计算正确的Laplacian特征值
  # 或者使用预计算的 laplacian_diags
  base:
    - full_attention        # 首选: 完整注意力矩阵
    - laplacian_diags       # 备选: 预计算的Laplacian对角线
  
  # 衍生特征 (如果使用full_attention，在运行时计算laplacian)
  derived: {}

# =============================================================================
# 方法参数 - 严格按照论文默认值
# =============================================================================
params:
  # 核心参数 (论文默认)
  top_k_eigenvalues: 100     # 每个(layer,head)提取的top-k特征值
  pca_dim: 512               # PCA降维目标维度
  response_only: true        # 只使用response部分的注意力
  
  # 分类器参数 (论文默认)
  max_iter: 2000
  class_weight: balanced

# =============================================================================
# 说明:
# 1. 原论文使用完整注意力矩阵计算Laplacian特征值
# 2. 公式: d_ii = Σ_{u>i} a_ui / (T-i), λ_i = d_ii - a_ii
# 3. 特征向量 = 所有层和头的top-k特征值拼接
# 4. 标准化 + PCA(512维) + LogisticRegression
# =============================================================================
