# =============================================================================
# Lookback Lens - Attention-based Hallucination Detection
# =============================================================================
# 论文: Looking Backwards: Attention-based Hallucination Detection
#
# 核心思想:
# 分析生成的 token 对 context 部分的注意力比率
# 幻觉 token 通常对 context 的注意力较低
# =============================================================================

name: lookback_lens
cls_path: src.methods.lookback_lens.LookbackLensMethod

classifier: logistic
random_seed: ${seed}

# -----------------------------------------------------------------------------
# 训练级别: both (原论文支持 token 级别，当前实现同时支持 sample 和 token)
# - sample: 样本级别聚合特征 + LogisticRegression
# - token:  逐token特征 + 分类器
# - both:   优先 token 级别，无标签时回退到 sample
# -----------------------------------------------------------------------------
level: both

# -----------------------------------------------------------------------------
# 特征需求
# -----------------------------------------------------------------------------
required_features:
  attention_diags: true      # 用于计算注意力比率
  laplacian_diags: false
  attention_entropy: false
  full_attention: false      # 可以从对角线近似计算
  hidden_states: false
  token_probs: false
  token_entropy: false

# -----------------------------------------------------------------------------
# 方法参数
# -----------------------------------------------------------------------------
params:
  # 比率类型: context_vs_generated, prompt_vs_response
  ratio_type: context_vs_generated
  
  # 使用哪些层: all, last, last_4, specific
  layers: all
  
  # 聚合方式: mean, max, min
  aggregation: mean
  
  # 是否归一化
  normalize: true
